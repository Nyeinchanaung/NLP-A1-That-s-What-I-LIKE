{"cells":[{"cell_type":"markdown","metadata":{"id":"zPu-326cr21G"},"source":["# Word2Vec (Skipgram )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UN5plLKGr21H"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1737348780972,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"StTUkNwUr21I","outputId":"d2b48faa-d25f-4514-e8d7-5b01064efdd7"},"outputs":[{"data":{"text/plain":["('1.26.4', '2.5.1+cu121')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["np.__version__, torch.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1737348780973,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"-UOIfknmr21I","outputId":"1ce5f14f-b961-4fd3-c6b6-1ed235eae1fe"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.10.0'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import matplotlib\n","matplotlib.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19957,"status":"ok","timestamp":1737348800923,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"8iVTlAP-sB0W","outputId":"80211c90-bd72-4f17-8651-61729e290930"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#connect to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8cunDY_sI5U"},"outputs":[],"source":["#import os\n","import os\n","\n","os.chdir('/content/drive/MyDrive/_NLP/NLP-A1-That-s-What-I-LIKE-st125553')"]},{"cell_type":"markdown","metadata":{"id":"1iO47716r21I"},"source":["## 1. Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3655,"status":"ok","timestamp":1737348804568,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"-nGk7PgTr21J","outputId":"99e4c205-9c83-42f3-e22a-bc7eb17e2582"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Load nltk\n","import nltk\n","\n","# download news category dataset from nltk\n","nltk.download('brown') # download brown corpus\n","nltk.download('punkt') # download punkt for tokenization\n","nltk.download('punkt_tab') # download punkt_tab for tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1737348804568,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"qsHRORRQr21J","outputId":"2477ab2e-7247-4c80-95aa-0709e4868e7d"},"outputs":[{"data":{"text/plain":["[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#1. tokenization\n","# import the news category dataset\n","from nltk.corpus import brown\n","corpus = brown.sents(categories='news')\n","corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1737348804568,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"ejJWtY1gr21J","outputId":"3277e11c-4d36-437d-e055-78af7e1dd129"},"outputs":[{"name":"stdout","output_type":"stream","text":["before vocabs_len: 14394\n","after vocabs_len: 14395\n"]}],"source":["#2. numeralization\n","#find unique words\n","flatten = lambda l: [item for sublist in l for item in sublist]\n","#assign unique integer\n","vocabs = list(set(flatten(corpus))) #all the words we have in the system - <UNK>\n","\n","print(f\"before vocabs_len: {len(vocabs)}\")\n","vocabs.append('<UNK>')\n","print(f\"after vocabs_len: {len(vocabs)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQnuMwjrr21J"},"outputs":[],"source":["#create handy mapping between integer and word\n","word2index = {v:idx for idx, v in enumerate(vocabs)}\n","#word2index['<UNK>'] # already in the system"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1737348804568,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"muzTYND-r21J","outputId":"311ee075-9993-4a98-b66c-7b4ffb556237"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<UNK>'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["index2word = {v:k for k, v in word2index.items()}\n","index2word[14394]"]},{"cell_type":"markdown","metadata":{"id":"vThyHl13r21K"},"source":["## 2. Prepare train data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZ-MDJO4r21K"},"outputs":[],"source":["#create pairs of center word, and outside word\n","\n","def random_batch(batch_size, corpus, window_size=2):\n","\n","    skipgrams = []\n","    outside = []\n","    #loop each corpus\n","    for doc in corpus:\n","        #look from the 2nd word until second last word\n","        for i in range(window_size, len(doc)-window_size):\n","            #center word\n","            center = word2index[doc[i]]\n","\n","            #outside words based on window size\n","            outside = [word2index[doc[i+j]] for j in range(-window_size, window_size+1) if i+j != i]\n","\n","            #for each of these two outside words, we gonna append to a list\n","            for each_out in outside:\n","                skipgrams.append([center, each_out])\n","                #center, outside1;   center, outside2\n","\n","    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n","\n","    inputs, labels = [], []\n","    for index in random_index:\n","        inputs.append([skipgrams[index][0]])\n","        labels.append([skipgrams[index][1]])\n","\n","    skipgrams\n","\n","    return np.array(inputs), np.array(labels), skipgrams"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjasRTR0r21K"},"outputs":[],"source":["window_size = 2\n","batch_size =   2\n","x, y , skipgrams = random_batch(batch_size, corpus, window_size)\n","#skipgrams"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"tOpE_1-7r21K","outputId":"519b3f5e-f0ab-41a4-a679-12e8c0bd9cb4"},"outputs":[{"data":{"text/plain":["(2, 1)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["x.shape  #batch_size, 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"gE9un3xnr21K","outputId":"959196b1-40c8-48c8-ceca-805192c4b980"},"outputs":[{"data":{"text/plain":["(2, 1)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["y.shape  #batch_size 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"9hLdigj-r21K","outputId":"a0a2dace-ff6b-4263-af80-18ca667ecbca"},"outputs":[{"data":{"text/plain":["(array([[13095],\n","        [ 8149]]),\n"," array([[12996],\n","        [13268]]))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x, y"]},{"cell_type":"markdown","metadata":{"id":"dXkPq84Cr21K"},"source":["## 3. Model\n","\n","$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}}\\log P(w_{t+j} | w_t; \\theta)$$\n","\n","where $P(w_{t+j} | w_t; \\theta) = $\n","\n","$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n","\n","where $o$ is the outside words and $c$ is the center word"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"2YaD3EKsr21K","outputId":"65450e27-69f2-49c9-eabf-f6a3a56274a5"},"outputs":[{"data":{"text/plain":["14395"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["voc_size = len(vocabs)\n","voc_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AE90hOjGr21K"},"outputs":[],"source":["embedding = nn.Embedding(voc_size, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"7zB_4btVr21K","outputId":"073fb681-eb99-4657-e344-6ffc9c34b9a5"},"outputs":[{"data":{"text/plain":["torch.Size([2, 1, 2])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["x_tensor = torch.LongTensor(x)\n","embedding(x_tensor).shape  #(batch_size, 1, emb_size)"]},{"cell_type":"markdown","metadata":{"id":"GQP0AkSar21K"},"source":["$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzJe-98gr21K"},"outputs":[],"source":["class Skipgram(nn.Module):\n","\n","    def __init__(self, voc_size, emb_size, word2index):\n","        super(Skipgram, self).__init__()\n","        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n","        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n","        self.word2index = word2index\n","\n","    def forward(self, center, outside, all_vocabs):\n","        center_embedding     = self.embedding_center(center)  #(batch_size, 1, emb_size)\n","        outside_embedding    = self.embedding_center(outside) #(batch_size, 1, emb_size)\n","        all_vocabs_embedding = self.embedding_center(all_vocabs) #(batch_size, voc_size, emb_size)\n","\n","        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n","        #batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1)\n","\n","        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n","        #batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, vocab_size)\n","\n","        lower_term_sum = torch.sum(torch.exp(lower_term), 1)  #(batch_size, 1)\n","\n","        loss = -torch.mean(torch.log(top_term / lower_term_sum))  #scalar\n","\n","        return loss\n","\n","    # def get_embed(self, word):\n","    #     try:\n","    #         index = self.word2index[word]\n","    #     except:\n","    #         index = self.word2index['<UNK>']\n","\n","    #     word = torch.LongTensor([self.word2index[word]])\n","\n","    #     embed_c = self.embedding_center(word)\n","    #     embed_o = self.embedding_outside(word)\n","    #     embed   = (embed_c + embed_o) / 2\n","    #     return embed[0][0].item(), embed[0][1].item()\n","\n","    def get_embed(self, word):\n","        try:\n","            index = self.word2index[word]\n","        except KeyError: # More specific exception handling\n","            index = self.word2index['<UNK>'] # If not found, default to <UNK>\n","\n","        # Use the index obtained, not looking up the word again\n","        word_tensor = torch.LongTensor([index])\n","\n","        embed_c = self.embedding_center(word_tensor)\n","        embed_o = self.embedding_outside(word_tensor)\n","        embed   = (embed_c + embed_o) / 2\n","        return embed[0][0].item(), embed[0][1].item()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"FfHj0X50r21K","outputId":"108a33d2-8800-4296-9033-b446e094c351"},"outputs":[{"name":"stdout","output_type":"stream","text":["14395\n"]},{"data":{"text/plain":["tensor([[    0,     1,     2,  ..., 14392, 14393, 14394],\n","        [    0,     1,     2,  ..., 14392, 14393, 14394]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#prepare all vocabs\n","\n","batch_size = 2\n","print(voc_size)\n","\n","def prepare_sequence(seq, word2index):\n","    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index['<UNK>'], seq))\n","    return torch.LongTensor(idxs)\n","\n","# Ensure the vocab size matches\n","all_vocabs = prepare_sequence(list(vocabs[:voc_size]), word2index).expand(batch_size, voc_size)\n","all_vocabs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"wnlKH9k2r21K","outputId":"557eae63-e3b8-4bb6-f7df-244dccd29140"},"outputs":[{"data":{"text/plain":["Skipgram(\n","  (embedding_center): Embedding(14395, 2)\n","  (embedding_outside): Embedding(14395, 2)\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model = Skipgram(voc_size, 2, word2index)\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kot2z98ar21L"},"outputs":[],"source":["input_tensor = torch.LongTensor(x)\n","label_tensor = torch.LongTensor(y)\n","#label_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CgIUekAr21L"},"outputs":[],"source":["loss = model(input_tensor, label_tensor, all_vocabs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1737348805698,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"sBP4LU-Er21L","outputId":"62f341d5-abe1-4e4e-e074-5c01834b29a5"},"outputs":[{"data":{"text/plain":["tensor(10.2614, grad_fn=<NegBackward0>)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["loss"]},{"cell_type":"markdown","metadata":{"id":"hrrkO0mMr21L"},"source":["## 4. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cx5UbIn-r21L"},"outputs":[],"source":["batch_size = 2\n","emb_size   = 2\n","window_size = 2\n","model      = Skipgram(voc_size, emb_size, word2index)\n","optimizer  = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZY1caBNr21L"},"outputs":[],"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"236Cmwsbr21L","outputId":"9d326904-dbd3-4d83-9080-0a64de36db4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 100 | Loss: 10.220242500305176 | time: 0m 0s\n","Epoch: 200 | Loss: 11.683025360107422 | time: 0m 0s\n","Epoch: 300 | Loss: 11.327919006347656 | time: 0m 0s\n","Epoch: 400 | Loss: 9.484025955200195 | time: 0m 0s\n","Epoch: 500 | Loss: 10.707599639892578 | time: 0m 0s\n","Epoch: 600 | Loss: 9.332622528076172 | time: 0m 0s\n","Epoch: 700 | Loss: 9.06155776977539 | time: 0m 0s\n","Epoch: 800 | Loss: 10.071385383605957 | time: 0m 0s\n","Epoch: 900 | Loss: 9.333847045898438 | time: 0m 0s\n","Epoch: 1000 | Loss: 10.528642654418945 | time: 0m 0s\n","Final Loss: 10.528643\n","Total time: 10 minutes 11 seconds\n"]}],"source":["import time\n","\n","num_epochs = 1000\n","total_loss = 0\n","start_time = time.time()\n","for epoch in range(num_epochs):\n","    start = time.time()\n","\n","    #get batch\n","    input_batch, label_batch, skipgrams = random_batch(batch_size, corpus, window_size)\n","    input_tensor = torch.LongTensor(input_batch)\n","    label_tensor = torch.LongTensor(label_batch)\n","\n","    #predict\n","    loss = model(input_tensor, label_tensor, all_vocabs)\n","\n","    #backprogate\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    #update alpha\n","    optimizer.step()\n","\n","    end = time.time()\n","\n","    #print time\n","    epoch_mins, epoch_secs = epoch_time(start, end)\n","\n","    #print the loss\n","    if (epoch + 1) % 100 == 0:\n","        print(f\"Epoch: {epoch + 1} | Loss: {loss} | time: {epoch_mins}m {epoch_secs}s\")\n","\n","    #calculate loss\n","    #total_loss += loss.item()\n","\n","    #calculate avg loss\n","    #avg_loss = total_loss / (epoch + 1)\n","\n","# print loss\n","print(f\"Final Loss: {loss:2.6f}\")\n","\n","# print(f\"Total loss: {total_loss:2.6f}\")\n","# print(f\"Avg loss: {avg_loss:2.6f}\")\n","# calculate time\n","end_time = time.time()\n","minutes, seconds = epoch_time(start_time, end_time)\n","print(f\"Total time: {minutes:2.0f} minutes {seconds:2.0f} seconds\")\n"]},{"cell_type":"markdown","metadata":{"id":"5oafCTAJr21L"},"source":["## 5. Testing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TxwbLImxr21L"},"outputs":[],"source":["vect = []\n","\n","for word in vocabs:\n","    vect.append(model.get_embed(word))\n","vect = np.array(vect)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hfNst6aur21L"},"outputs":[],"source":["#scipy version\n","from scipy import spatial\n","\n","def cos_sim(a, b):\n","    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n","    return cos_sim\n","\n","def cos_sim_scores(vect_space, target_vect):\n","    scores = []\n","    for each_vect in vect_space:\n","        each_vect = tuple(each_vect)\n","        target_vect=tuple(target_vect)\n","        scores.append(cos_sim(target_vect, each_vect))\n","\n","    return np.array(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WzGdharur21L"},"outputs":[],"source":["def similarity(model, data):\n","    words = data.split(\" \")\n","\n","    embed0 = np.array(model.get_embed(words[0]))\n","    embed1 = np.array(model.get_embed(words[1]))\n","    embed2 = np.array(model.get_embed(words[2]))\n","\n","    sim_vect = embed1 - embed0 + embed2\n","\n","    sim_scores = cos_sim_scores(vect, sim_vect)\n","    max_score_idx = np.argmax(sim_scores)\n","    sim_word = index2word[max_score_idx]\n","\n","    result = False\n","    if sim_word == words[3]:\n","        result = True\n","\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"4AHpYyi8r21L"},"source":["### Semantic Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"V4AS-rdkBNku"},"outputs":[],"source":["semantic_file = \"data/word-test-semantic.txt\"\n","# open file\n","with open(semantic_file, \"r\") as file:\n","    sem_file = file.readlines()\n","    #send semantic into vector\n","\n","semantic = []\n","for sent in sem_file:\n","    semantic.append(sent.strip())\n","\n","#semantic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Od1LShJUr21L"},"outputs":[],"source":["sem_count = len(semantic)\n","#sem_total\n","sem_correct = 0\n","for sent in semantic:\n","    if similarity(model, sent):\n","        sem_correct += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"99sRWlNZr21O","outputId":"041a6420-0954-44fd-ef97-e6a3dca61896"},"outputs":[{"name":"stdout","output_type":"stream","text":["Semantic accuracy: 0.00\n","Semantic correct: 0\n","Semantic count: 506\n"]}],"source":["sem_accuracy = sem_correct / sem_count\n","print(f\"Semantic accuracy: {sem_accuracy:2.2f}\")\n","print(f\"Semantic correct: {sem_correct}\")\n","print(f\"Semantic count: {sem_count}\")"]},{"cell_type":"markdown","metadata":{"id":"b-0cW9U0r21P"},"source":["### Syntatic Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vj4Pq16ABPdh"},"outputs":[],"source":["syntatic_file = \"data/word-test-syntatic.txt\"\n","# open file\n","with open(syntatic_file, \"r\") as file:\n","    syn_file = file.readlines()\n","\n","syntatic = []\n","for sent in syn_file:\n","    syntatic.append(sent.strip())\n","#syntatic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NYvpzmUWr21P"},"outputs":[],"source":["syn_count = len(syntatic)\n","syn_correct = 0\n","for sent in syntatic:\n","    if similarity(model, sent):\n","        syn_correct += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JV_uhcOZr21P","outputId":"4972af73-2306-487c-c316-070e18a4c3f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Syntatic accuracy: 0.00\n","Syntatic correct: 0\n","Syntatic count: 1560\n"]}],"source":["syn_accuracy = syn_correct / syn_count\n","print(f\"Syntatic accuracy: {syn_accuracy:2.2f}\")\n","print(f\"Syntatic correct: {syn_correct}\")\n","print(f\"Syntatic count: {syn_count}\")"]},{"cell_type":"markdown","metadata":{"id":"43vi43iFBzwt"},"source":["### Similarity Test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qUokx2ibBeRd"},"outputs":[],"source":["similarity_file = \"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n","# open file\n","with open(similarity_file, \"r\") as file:\n","    sim_file = file.readlines()\n","\n","similarity = []\n","for sent in sim_file:\n","    similarity.append(sent.strip())\n","#syntatic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZjCaf-1eCX4q"},"outputs":[],"source":["def similarity_test(model, test_data):\n","    words = test_data.split(\"\\t\")\n","\n","    embed0 = np.array(model.get_embed(words[0].strip()))\n","    embed1 = np.array(model.get_embed(words[1].strip()))\n","\n","    model_result = embed1 @ embed0.T\n","    sim_result = float(words[2].strip())\n","\n","    return sim_result, model_result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YlI2qBp0CZu3"},"outputs":[],"source":["sim_scores = []\n","model_scores = []\n","for sent in similarity:\n","    sim_result, model_result = similarity_test(model, sent)\n","\n","    sim_scores.append(sim_result)\n","    model_scores.append(model_result)\n","\n","    # add human judgment\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1uHSCpduCb8C","outputId":"39375911-67fb-4264-8589-53225d248394"},"outputs":[{"name":"stdout","output_type":"stream","text":["The correlation result is 0.08.\n"]}],"source":["from scipy.stats import spearmanr\n","\n","corr = spearmanr(sim_scores, model_scores)[0]\n","\n","print(f\"The correlation result is {corr:2.2f}.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L5Tg2C2A97Bq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YM2njafH9pm1","outputId":"9eb7961d-caaf-4a54-b3e1-9465cd5b518d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The correlation result is 0.05.\n"]}],"source":["corr = np.corrcoef(sim_scores, model_scores)[0][1]\n","\n","print(f\"The correlation result is {corr:2.2f}.\")"]},{"cell_type":"markdown","metadata":{"id":"wpAxDxqir21P"},"source":["## 6. Save the model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0vioMHa0r21P"},"outputs":[],"source":["# Saving the model for testing\n","torch.save(model.state_dict(), 'app/models/w2v-skipgram.model')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GY3aTpsir21P"},"outputs":[],"source":["skipgram_args = {\n","    'voc_size': voc_size,\n","    'emb_size': emb_size,\n","    'word2index': word2index,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"44qSNvs9r21P"},"outputs":[],"source":["import pickle\n","pickle.dump(skipgram_args, open('app/models/w2v-skipgram.args', 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wuQlI22rr21P","outputId":"4da456ac-da5b-4300-e701-fd43f7bc804a"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-45-8165938d23cf>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  load_model.load_state_dict(torch.load('app/models/w2v-skipgram.model'))\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["skg_args = pickle.load(open('app/models/w2v-skipgram.args', 'rb'))\n","load_model = Skipgram(**skipgram_args)\n","load_model.load_state_dict(torch.load('app/models/w2v-skipgram.model'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SCUMdKFIr21P","outputId":"6c3d1649-192b-45a9-ad20-53f6fa460fb9"},"outputs":[{"data":{"text/plain":["(-1.3755590915679932, 1.0446343421936035)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["keyword = load_model.get_embed('The')\n","keyword"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tYdQ-W6GroVf"},"outputs":[],"source":["# select similar wrod from model result\n"]},{"cell_type":"markdown","metadata":{"id":"Ci6G0da0HhhB"},"source":["## 8. Calculate MSE"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPSrZb2PgN67","executionInfo":{"status":"ok","timestamp":1737349743133,"user_tz":-420,"elapsed":346,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"a1e97b1a-0578-4cdb-ff43-c76616966ecb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spearman correlation: 0.0760, p-value: 0.2815\n","Mean Squared Error (MSE): 31.9355, Yture MSE: 0.0000\n","Correlation for Y-True: 1.0000, p-value: 0.0000\n"]}],"source":["from sklearn.metrics import mean_squared_error\n","import pandas as pd\n","from scipy.stats import spearmanr\n","import numpy as np\n","\n","# Load the dataset\n","file_path = \"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n","similarity_data = pd.read_csv(file_path, sep='\\t', names=['word1', 'word2', 'similarity'])\n","\n","def compute_dot_product(model, word1, word2):\n","    \"\"\"Compute dot product between embeddings of two words.\"\"\"\n","    embedding1 = model.get_embed(word1)\n","    embedding2 = model.get_embed(word2)\n","    if embedding1 is None or embedding2 is None:\n","        return 0.0  # Default to zero for missing embeddings\n","    return np.dot(np.array(embedding1), np.array(embedding2))\n","\n","def compute_model_similarities(model, data):\n","    \"\"\"Compute similarities using the model.\"\"\"\n","    model_similarities = []\n","    for _, row in data.iterrows():\n","        dot_product = compute_dot_product(model, row['word1'], row['word2'])\n","        model_similarities.append(dot_product)\n","    return model_similarities\n","\n","# Prepare data for word embedding models\n","gold_standard_similarities = similarity_data['similarity'].values  # Y-true\n","model_similarities = compute_model_similarities(model, similarity_data)\n","\n","# Calculate Spearman's rank correlation\n","correlation, p_value = spearmanr(model_similarities, gold_standard_similarities)\n","\n","# Calculate Mean Squared Error (MSE)\n","mse = mean_squared_error(gold_standard_similarities, model_similarities)\n","ytrue_mse = mean_squared_error(gold_standard_similarities, gold_standard_similarities)\n","\n","# Output results\n","print(f\"Spearman correlation: {correlation:.4f}, p-value: {p_value:.4f}\")\n","print(f\"Mean Squared Error (MSE): {mse:.4f}, Yture MSE: {ytrue_mse:.4f}\")\n","\n","# Y-true values from the dataset\n","y_true = similarity_data['similarity'].values\n","\n","# Calculate correlation for Y-True\n","ytrue_correlation, ytrue_p_value = spearmanr(gold_standard_similarities, gold_standard_similarities)\n","print(f\"Correlation for Y-True: {ytrue_correlation:.4f}, p-value: {ytrue_p_value:.4f}\")\n"]}],"metadata":{"colab":{"machine_shape":"hm","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}