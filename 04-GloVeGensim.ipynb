{"cells":[{"cell_type":"markdown","metadata":{"id":"kFVBR4werm5D"},"source":["# GloVe (Gensim)\n","\n","For looking at word vectors, we'll use **Gensim**. **Gensim** isn't really a deep learning package. It's a package for for word and text similarity modeling, which started with (LDA-style) topic models and grew into SVD and neural word representations. But its efficient and scalable, and quite widely used.   We gonna use **GloVe** embeddings, downloaded at [the Glove page](https://nlp.stanford.edu/projects/glove/). They're inside [this zip file](https://nlp.stanford.edu/data/glove.6B.zip)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLie9l07rm5H"},"outputs":[],"source":["import numpy as np\n","from gensim.test.utils import datapath\n","from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19510,"status":"ok","timestamp":1737277040846,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"biEMBIZfx5SQ","outputId":"844b1e3a-0840-4646-ac3b-c511e9b31452"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#connect to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeVVe0Xpx9du"},"outputs":[],"source":["#import os\n","import os\n","\n","os.chdir('/content/drive/MyDrive/_NLP/NLP-A1-That-s-What-I-LIKE-st125553')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8575,"status":"ok","timestamp":1737277313591,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"gZcgNjHuyOrr","outputId":"90e663ec-7314-456a-8881-02d42fe2d5b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/danielwillgeorge/glove6b100dtxt?dataset_version_number=1...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 131M/131M [00:01<00:00, 117MB/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting files...\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Path to dataset files: /root/.cache/kagglehub/datasets/danielwillgeorge/glove6b100dtxt/versions/1\n"]}],"source":["# download glove.6B.100d.txt\n","import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"danielwillgeorge/glove6b100dtxt\")\n","\n","print(\"Path to dataset files:\", path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJa-6_36yAdm"},"outputs":[],"source":["#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n","\n","glove_file = datapath('/root/.cache/kagglehub/datasets/danielwillgeorge/glove6b100dtxt/versions/1/glove.6B.100d.txt')  #search on the google\n","model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1737277567596,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"jGFF4l0bz3nR","outputId":"d85e79fa-c7d8-416d-aebf-0bea74afcc60"},"outputs":[{"data":{"text/plain":["(100,)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#return the vectors\n","model['coffee'].shape"]},{"cell_type":"markdown","metadata":{"id":"UXV_Cfef2r47"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"joBKTUU-2xH1"},"source":["### Semantic Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJm-6vns0GNX"},"outputs":[],"source":["semantic_file = \"data/word-test-semantic.txt\"\n","# open file\n","with open(semantic_file, \"r\") as file:\n","    sem_file = file.readlines()\n","    #send semantic into vector\n","\n","semantic = []\n","for sent in sem_file:\n","    semantic.append(sent.strip())\n","\n","#semantic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67iLNh4F0IWU"},"outputs":[],"source":["sem_count = len(semantic)\n","sem_correct = 0\n","#sem_total\n","\n","for sent in semantic:\n","    sent = sent.lower()\n","    words = sent.split(\" \")\n","\n","    try:\n","        result = model.most_similar(positive=[words[1], words[2]], negative=[words[0]])[0][0]\n","    except:\n","        result = \"<UNK>\"\n","\n","    if result == words[3]:\n","        sem_correct += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1737289492056,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"q2mCjzNX3BD3","outputId":"8807ab61-57a8-4229-80d7-b63cb7b052a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Semantic accuracy: 0.53\n","Semantic correct: 269\n","Semantic count: 506\n"]}],"source":["sem_accuracy = sem_correct / sem_count\n","print(f\"Semantic accuracy: {sem_accuracy:2.2f}\")\n","print(f\"Semantic correct: {sem_correct}\")\n","print(f\"Semantic count: {sem_count}\")"]},{"cell_type":"markdown","metadata":{"id":"399vhwmb3hDj"},"source":["### Syntatic Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20rsezX53g0N"},"outputs":[],"source":["syntatic_file = \"data/word-test-syntatic.txt\"\n","# open file\n","with open(syntatic_file, \"r\") as file:\n","    syn_file = file.readlines()\n","\n","syntatic = []\n","for sent in syn_file:\n","    syntatic.append(sent.strip())\n","#syntatic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxvHfn5y3V7L"},"outputs":[],"source":["syn_count = len(syntatic)\n","syn_correct = 0\n","\n","for sent in syntatic:\n","    sent = sent.lower()\n","    words = sent.split(\" \")\n","\n","    try:\n","        result = model.most_similar(positive=[words[1], words[2]], negative=[words[0]])[0][0]\n","    except:\n","        result = \"<UNK>\"\n","\n","    if result == words[3]:\n","        syn_correct += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1737278650451,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"t7sMf3Ns37eL","outputId":"c4aae4f1-6df4-423d-9f94-bb34785f80be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Syntatic accuracy: 0.55\n","Syntatic correct: 865\n","Syntatic count: 1560\n"]}],"source":["syn_accuracy = syn_correct / syn_count\n","print(f\"Syntatic accuracy: {syn_accuracy:2.2f}\")\n","print(f\"Syntatic correct: {syn_correct}\")\n","print(f\"Syntatic count: {syn_count}\")"]},{"cell_type":"markdown","metadata":{"id":"fnIg50bo4Qzf"},"source":["### Similarity Test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Wbnv2RC4Red"},"outputs":[],"source":["similarity_file = \"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n","# open file\n","with open(similarity_file, \"r\") as file:\n","    sim_file = file.readlines()\n","\n","similarity = []\n","for sent in sim_file:\n","    similarity.append(sent.strip())\n","#syntatic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1737279066234,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"Vjfyu5l65GrG","outputId":"5a30a244-2665-486f-fa5a-af4072572bc3"},"outputs":[{"data":{"text/plain":["100"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# default_vector = np.zeros(model.vector_size)\n","# len(default_vector)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzpNXH3x4V02"},"outputs":[],"source":["# def similarity_test(model, test_data):\n","#     words = test_data.split(\"\\t\")\n","\n","#     embed0 = np.array(model.get_vector(words[0].strip()))\n","#     embed1 = np.array(model.get_vector(words[1].strip()))\n","\n","#     model_result = embed1 @ embed0.T\n","#     sim_result = float(words[2].strip())\n","\n","#     return sim_result, model_result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlMr6-Uv6hrm"},"outputs":[],"source":["default_vector = np.zeros(model.vector_size)\n","\n","def similarity_test(model, test_data):\n","    words = test_data.lower().split(\"\\t\")\n","\n","    default_vector = np.zeros(model.vector_size)\n","    try:\n","        embed0 = model.get_vector(words[0].strip())\n","        embed1 = model.get_vector(words[1].strip())\n","    except:\n","        embed0 = default_vector\n","        embed1 = default_vector\n","\n","\n","    similarity_model = embed1 @ embed0.T\n","    similarity_provided = float(words[2].strip())\n","\n","    return similarity_provided, similarity_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-e3j7fF58-F"},"outputs":[],"source":["sim_scores = []\n","model_scores = []\n","for sent in similarity:\n","    sim_result, model_result = similarity_test(model, sent)\n","\n","    sim_scores.append(sim_result)\n","    model_scores.append(model_result)"]},{"cell_type":"code","source":["print(sim_result)\n","print(model_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqvtNHQiFHeC","executionInfo":{"status":"ok","timestamp":1737298863624,"user_tz":-420,"elapsed":302,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"2aed3c66-56d2-4038-f520-4151f242fdd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.23\n","1.4002881\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1737298920244,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"4dmVpf_y5_fh","outputId":"2878f8fb-3520-4054-de84-63c67ee9b8e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["The correlation result is 0.5431.\n"]}],"source":["from scipy.stats import spearmanr\n","\n","corr = spearmanr(sim_scores, model_scores)[0]\n","\n","print(f\"The correlation result is {corr:2.4f}.\")"]},{"cell_type":"markdown","source":["## Test P Value"],"metadata":{"id":"TIk_hqylD__T"}},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import spearmanr\n","\n","def compute_cosine_similarity(model, word1, word2):\n","    \"\"\"Compute cosine similarity between word embeddings of two words.\"\"\"\n","    try:\n","        vec1 = model.get_vector(word1)\n","        vec2 = model.get_vector(word2)\n","        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n","    except KeyError:\n","        # Handle missing words in the model\n","        return 0.0\n","\n","def compute_model_similarities(model, data):\n","    \"\"\"Compute similarities using the model.\"\"\"\n","    similarities = []\n","    for _, row in data.iterrows():\n","        similarity = compute_cosine_similarity(model, row['word1'], row['word2'])\n","        similarities.append(similarity)\n","    return similarities"],"metadata":{"id":"Nm6nX9VpGxGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = \"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n","similarity_data = pd.read_csv(file_path, sep='\\t', names=['word1', 'word2', 'similarity'])\n","\n","# Display sample data\n","print(similarity_data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hr4ODY_EGyM6","executionInfo":{"status":"ok","timestamp":1737299306675,"user_tz":-420,"elapsed":332,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"bf418b02-dba2-4998-f297-ede65349b134"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        word1  word2  similarity\n","0       tiger    cat        7.35\n","1       tiger  tiger       10.00\n","2       plane    car        5.77\n","3       train    car        6.31\n","4  television  radio        6.77\n"]}]},{"cell_type":"code","source":["gold_standard_similarities = similarity_data['similarity'].values\n","model_similarities = compute_model_similarities(model, similarity_data)\n","\n","# Compute Spearman correlation\n","correlation, p_value = spearmanr(model_similarities, gold_standard_similarities)\n","\n","print(f\"Spearman correlation (GloVe Gensim): {correlation:.4f}\")\n","print(f\"P-value: {p_value:.4e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOJD4eCrG9I5","executionInfo":{"status":"ok","timestamp":1737300937227,"user_tz":-420,"elapsed":304,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"a2329fd3-4271-4de8-8ca4-533d3258b188"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spearman correlation (GloVe Gensim): 0.5800\n","P-value: 1.2167e-19\n"]}]},{"cell_type":"markdown","metadata":{"id":"6SdaFb9j7cxA"},"source":["## Save the result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1511,"status":"ok","timestamp":1737279903845,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"bYP-OvUk7e-G","outputId":"add8c174-33db-4b37-b9d5-7d0c6c7ec7f6"},"outputs":[{"data":{"text/plain":["[('james', 0.8570922017097473),\n"," ('george', 0.8181617259979248),\n"," ('thomas', 0.8109301328659058),\n"," ('william', 0.8084547519683838),\n"," ('paul', 0.8058123588562012),\n"," ('henry', 0.7886716723442078),\n"," ('edward', 0.7804422378540039),\n"," ('peter', 0.7743206024169922),\n"," ('richard', 0.7710520625114441),\n"," ('robert', 0.767145037651062)]"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["import pickle\n","\n","# Save the model\n","pickle.dump(model,open('app/models/gensim.model','wb'))\n","\n","load_model = pickle.load(open('app/models/gensim.model', 'rb'))\n","load_model.most_similar('james')"]},{"cell_type":"markdown","source":["## Calculate MSE"],"metadata":{"id":"Q0yLB2Vj70MI"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","import pandas as pd\n","from scipy.stats import spearmanr\n","import numpy as np\n","\n","# Load the dataset\n","file_path = \"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n","similarity_data = pd.read_csv(file_path, sep='\\t', names=['word1', 'word2', 'similarity'])\n","\n","def compute_dot_product(model, word1, word2):\n","    \"\"\"Compute dot product between embeddings of two words.\"\"\"\n","    try:\n","        vec1 = model.get_vector(word1)\n","        vec2 = model.get_vector(word2)\n","        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n","    except KeyError:\n","        # Handle missing words in the model\n","        return 0.0\n","    if embedding1 is None or embedding2 is None:\n","        return 0.0  # Default to zero for missing embeddings\n","    return np.dot(np.array(embedding1), np.array(embedding2))\n","\n","# function to calculate the similarities\n","def compute_model_similarities(model, data):\n","    \"\"\"Compute similarities using the model.\"\"\"\n","    model_similarities = []\n","    for _, row in data.iterrows():\n","        dot_product = compute_dot_product(model, row['word1'], row['word2'])\n","        model_similarities.append(dot_product)\n","    return model_similarities\n","\n","# Prepare data for word embedding models\n","gold_standard_similarities = similarity_data['similarity'].values  # Y-true\n","model_similarities = compute_model_similarities(model, similarity_data)\n","\n","# Calculate Spearman's rank correlation\n","correlation, p_value = spearmanr(model_similarities, gold_standard_similarities)\n","\n","# Calculate Mean Squared Error (MSE)\n","mse = mean_squared_error(gold_standard_similarities, model_similarities)\n","ytrue_mse = mean_squared_error(gold_standard_similarities, gold_standard_similarities)\n","\n","# Output results\n","print(f\"Spearman correlation: {correlation:.4f}, p-value: {p_value:.4f}\")\n","print(f\"Mean Squared Error (MSE): {mse:.4f}, Yture MSE: {ytrue_mse:.4f}\")\n","\n","# Calculate correlation for Y-True\n","ytrue_correlation, ytrue_p_value = spearmanr(gold_standard_similarities, gold_standard_similarities)\n","print(f\"Correlation for Y-True: {ytrue_correlation:.4f}, p-value: {ytrue_p_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEzSJ5YIcRHD","executionInfo":{"status":"ok","timestamp":1737308380980,"user_tz":-420,"elapsed":315,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"7c0594fc-011d-4e10-c5cc-5deb69276027"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spearman correlation: 0.5800, p-value: 0.0000\n","Mean Squared Error (MSE): 27.8081, Yture MSE: 0.0000\n","Correlation for Y-True: 1.0000, p-value: 0.0000\n"]}]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"dsai","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"}}},"nbformat":4,"nbformat_minor":0}